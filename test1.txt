from fastapi import FastAPI, Form, Request, Depends, HTTPException
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import requests
import json
import urllib3
import logging
from kubernetes import client, config
from openshift.dynamic import DynamicClient
from ocploginconfiguration import ocploginconfiguration
from typing import Optional, List

# Disable SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

app = FastAPI()

# Set up Jinja2 for templates
templates = Jinja2Templates(directory="templates")
app.mount("/static", StaticFiles(directory="static"), name="static")

# Sample OpenShift Clusters (Modify as needed)
CLUSTERS = {
    "Cluster1": "https://api.cluster1.example.com",
    "Cluster2": "https://api.cluster2.example.com"
}

SCANPORTAL_API_BASE = "https://scanportal.example.com"

def get_openshift_token(username, password):
    """Retrieve OpenShift token."""
    try:
        logging.info("Retrieving OpenShift token...")
        token = ocploginconfiguration(ocp_username=username, ocp_password=password)
        return token if token else None
    except Exception as e:
        logging.error(f"Error retrieving OpenShift token: {e}")
        return None

def get_image_tags(registry, image_name, username, password):
    """Retrieve available tags for an image from the registry."""
    try:
        url = f"https://{registry}/v2/{image_name}/tags/list"
        response = requests.get(url, auth=(username, password), verify=False)

        if response.status_code == 200:
            return response.json().get("tags", [])
        return []
    except Exception as e:
        logging.error(f"Error retrieving tags: {e}")
        return []

def check_image_exists(registry, image_name, tag, token):
    """Check if the image exists in the registry before scanning."""
    try:
        url = f"https://{registry}/v2/{image_name}/manifests/{tag}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers, verify=False)
        return response.status_code == 200
    except Exception as e:
        logging.error(f"Error checking image existence: {e}")
        return False

def get_pods_and_deployments(cluster, image, token):
    """Retrieve pods and deployments across all namespaces using the image."""
    try:
        config.load_kube_config()
        k8s_client = client.ApiClient()
        dyn_client = DynamicClient(k8s_client)

        projects = dyn_client.resources.get(api_version="project.openshift.io/v1", kind="Project").get().items
        matched_pods, matched_deployments = [], []

        for project in projects:
            namespace = project.metadata.name
            v1_pods = dyn_client.resources.get(api_version="v1", kind="Pod").get(namespace=namespace).items
            v1_deployments = dyn_client.resources.get(api_version="apps.openshift.io/v1", kind="DeploymentConfig").get(namespace=namespace).items

            for pod in v1_pods:
                if image in str(pod):
                    matched_pods.append(f"{namespace}/{pod.metadata.name}")

            for deploy in v1_deployments:
                if image in str(deploy):
                    matched_deployments.append(f"{namespace}/{deploy.metadata.name}")

        return matched_pods, matched_deployments
    except Exception as e:
        logging.error(f"Error retrieving pods and deployments: {e}")
        return [], []

def delete_vulnerable_resources(namespace, pods, deployments, token):
    """Delete pods and DeploymentConfigs if image is vulnerable."""
    try:
        config.load_kube_config()
        k8s_client = client.ApiClient()
        dyn_client = DynamicClient(k8s_client)

        v1_pods = dyn_client.resources.get(api_version="v1", kind="Pod")
        v1_deployments = dyn_client.resources.get(api_version="apps.openshift.io/v1", kind="DeploymentConfig")

        deleted_pods, deleted_deployments = [], []

        for pod in pods:
            v1_pods.delete(name=pod.split("/")[-1], namespace=namespace)
            deleted_pods.append(pod)

        for deploy in deployments:
            v1_deployments.delete(name=deploy.split("/")[-1], namespace=namespace)
            deleted_deployments.append(deploy)

        return deleted_pods, deleted_deployments
    except Exception as e:
        logging.error(f"Error deleting resources: {e}")
        return [], []

@app.post("/scan")
async def scan_image(request: Request, username: str = Form(...), password: str = Form(...),
                     cluster: str = Form(...), registry: str = Form(...), image_name: str = Form(...),
                     tag: Optional[str] = Form(None)):

    openshift_token = get_openshift_token(username, password)
    if not openshift_token:
        raise HTTPException(status_code=401, detail="Failed to retrieve OpenShift token")

    tags = [tag] if tag else get_image_tags(registry, image_name, username, password)
    if not tags:
        return templates.TemplateResponse("results.html", {"request": request, "error": "Image not found."})

    scan_results, pods, deployments, deleted_pods, deleted_deployments = [], [], [], [], []

    for tag in tags:
        if check_image_exists(registry, image_name, tag, openshift_token):
            pods, deployments = get_pods_and_deployments(cluster, f"{registry}/{image_name}:{tag}", openshift_token)
            
            if pods or deployments:
                del_pods, del_deploys = delete_vulnerable_resources(cluster, pods, deployments, openshift_token)
                deleted_pods.extend(del_pods)
                deleted_deployments.extend(del_deploys)

    return templates.TemplateResponse("results.html", {
        "request": request, "pods": pods, "deployments": deployments,
        "deleted_pods": deleted_pods, "deleted_deployments": deleted_deployments
    })
